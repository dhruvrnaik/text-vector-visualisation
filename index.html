---
layout: home
search_exclude: true
---
<html>

<style>
	table, th, td {
    width: 50%;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid black;
    border-collapse: collapse;
}

</style>

<!-- <html>
   <head>
      <style>
         table, td, th {
            border: 1px solid black;
            width: 300px;
         }
      </style>
   </head>
   <body>
      <h1>Our Technologies</h1>
      <table>
         <tr>
            <th>IDE</th>
            <th>Database</th>
         </tr>
         <tr>
            <td style="text-align:center">NetBeans</td>
            <td style="text-align:center">MySQL</td>
         </tr>
      </table>
   </body>
</html> -->


<body>
<center><h1><b>Exploration and Visualisation Of Word Vectors</b></h1></center>


The complete exploration-pipeline is represented as:


<!-- <img src="images/flowchart.png" alt="Flowchart">  -->
<div style="display: flex; justify-content: center;">
  <img src="images/flowchart.png" alt = "Flowchart" style="width: auto; height: 200px;" />
</div>


<h2><b>Requirements and Dependencies</b></h2>



<h4>To run the code the following are a <b><i>must</i></b> to be installed:</h4>

<p>   
<table>
  <tr>
    <th><h4><b>Serial No</b></h4></th>
    <th><h4><b>Libraries to Install</b></h4></th> 
  </tr>
  <tr>
    <td><h4>1.</h4></td>
    <td style="text-align: center"><h4><a href="https://fasttext.cc/docs/en/support.html">FastText</a></h4></td>  
  </tr>
  <tr>
    <td><h4>2.</h4></td>
    <td style="text-align: center"><h4><a href="https://www.tensorflow.org/api_docs">TensorFlow</a></h4></td>
  </tr>
  <tr>
    <td><h4>3.</h4></td>
    <td style="text-align: center"><h4><a href="https://spacy.io/usage">Spacy</a></h4></td>
  </tr>
</table>
</p>



<h2><b>Steps to Execute</b></h2>

<h4>
<p>	
1. Download the <i>bbc-text.csv</i> dataset from <a href="https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv">here</a> or it can be downloaded through the terminal if gcloud is already setup by the command: <br><code>gsutil cp gs:​//​dataset-uploader​/bbc/​bbc-text.csv [path to notebook directory]</code>.
</p>
<p>
2. Make sure all the libraries are present/updated according to the <u>requirements</u> mentioned above.
</p>
<p>
3. To train the model according to the above complete dataset using FastText, run the notebook given <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/fasttext/python/2020/05/20/fasttext-model-train.html">here</a>. A pre-trained model based on the dataset can be downloaded from <a href="https://learnermanipal-my.sharepoint.com/:u:/g/personal/rohit_rajesh_learner_manipal_edu/EXiXnzOeVN9KsdWpoFgr4CABfblCuo8RamsdLM9NUyatyA?e=yjkplM">here</a> and there is also a pre trained sample model called <u>sample-fasttextmodel.bin</u> in the repository.
</p>
<p>
<i>Note: The sample pre trained model in the link is trained with dimension of word vector = 300 and in the repository is trained with dimension of word vector = 12 (because of 100 MB github file size per push),so prefer downloading the model from the link.</i>
</p>
<p>
According to the FastText documentation:
</p>
<p>
<blockquote><h4>The most important parameters of the model are its dimension and the range of size for the subwords. The dimension controls the size of the vectors, the larger they are the more information they can capture but requires more data to be learned. As any value in the 100-300 range is popular, the notebook has been implemented with dimension equal to 300.</h4></blockquote>
</p>
<p>
<b>Steps 4,5 and 6 differ for TF1 and TF 2. After that, the steps are same.</b>
</p>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF1 [<font color='red'>NOT ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb1files</u> in the same directory of the notebooks​ and keep it empty. It will store all the tensorflow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​<u>tb1vis.ipynb</u>​.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb1files/</code>
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb1.png" alt="TB1 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF2 [<font color='green'>ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb2files</u> in the same directory of the notebooks​ and keep it empty. It will store all the tensorflow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​<u>tb2vis.ipynb</u>​.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb2files/</code>.
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb2.png" alt="TB2 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<p>
7. Open the local host URL link present in the last line. For Example: <code>http://localhost:6008/</code> [in TB1 Command image].
</p>
<p>
8. The local host website shown below will run. From the drop-down which reads Inactive, press and go to Projector as depicted by the arrow in the image below.
</p>

<div style="display: flex; justify-content: center;">
<img src="images/projector.png" alt="Projector Image" style="width: auto; height: 250px;" />
</div>

<p>
9. This will plot the words according to their embedding values shown in the 3D graph of tensorboard. The nearest neighbours of a word can be found by typing the word in the search bar, as done for the example <b>‘plea’</b> shown below.
</p>


<div style="display: flex; justify-content: center;">
  <img src="images/tbvis.png" alt = "Visualisation on Tensorboard" style="width: auto; height: 250px;" />
</div>


That's it, folks!
</h4>
<hr>
</body>
<h1> Posts </h1>
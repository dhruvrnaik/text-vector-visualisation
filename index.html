---
layout: home
search_exclude: true
---
<html>
<!-- 
<style>
	table, th, td {
    width: 50%;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid black;
    border-collapse: collapse;
}
</style> -->



<body>
<center><h1><b>Exploration and Visualisation Of Word Vectors</b></h1></center>
<p>
<h4>
A popular idea in machine learning is to represent words by vectors. FastText vectors capture hidden information about a language, like <b><i>word analogies</i></b> or <b><i>semantic</i></b>.
</h4>
</p>

<p>
<h4>
This hidden information helps us in :
<ol>
<li>Finding and extracting misspellings of a target word in the entire dataset.</li>
<li>Finding words that occur commonly in context (in neighbour) to the target word. This gives an intuition of the type of semantic information the vectors can capture.</li>
<li>Finding similarity between different words given as a cosine of the angle between the word vectors. The word with the cosine distance closer to 1 is a more similar word to the target word.</li>
</ol>
</h4>
</p>

<p>
<h4>
Visualising the vectors on the TensorBoard gives us a 3-dimensional view of a 300-dimensional word vector. It makes us visualise the top misspellings for the target word as well as the cosine distance of the misspelling to the target word. 
</h4>
</p>

<p>
<h4>
This practice is beneficial when we want to cover the maximum number of sentences which have the same semantic information or intent in the dataset. This is called <b>coverage</b> of the intent in the dataset. By using the exploration-pipeline [shown below], the coverage for an intent can be increased.
</h4>
</p>

<p>
<h4>The complete exploration-pipeline is diagrammatically represented as:</h4>
</p>

<div style="display: flex; justify-content: center;">
  <img src="images/flowchart.png" alt = "Flowchart" style="width: auto; height: 170px; border: 1px;" />
</div>

 <p>
<h4>
In <a href="https://verloop.io/">Verloop</a>, we observed that the exploration-pipeline for different intents helped us in seeing a coverage jump of about <b>~10-11%</b> from the dataset the machine learning model wasn't able to cover after it's first run of prediction. This guaranteed the success in working of the pipeline. 
</h4>
</p>
<p>
<h4>
To begin with the execution, it is important to know the pre-requisites which can be known from <a href="https://rohetoric.github.io/text-vector-visualisation/markdown/jupyter/fasttext/tensorflow/tensorboard/2020/05/18/ExecutionSteps.html">here</a>.
</h4>
</p>

<hr>

</body>
<h1> Posts </h1>

<!-- <h2><b>Requirements and Dependencies</b></h2>



<h4>To run the code the following are a <b><i>must</i></b> to be installed:</h4>

<p>   
<table>
  <tr>
    <th><h4><b>Serial No</b></h4></th>
    <th><h4><b>Libraries to Install</b></h4></th> 
  </tr>
  <tr>
    <td style="text-align: center"><h4>1.</h4></td>
    <td style="text-align: center"><h4><a href="https://fasttext.cc/docs/en/support.html">FastText</a></h4></td>  
  </tr>
  <tr>
    <td style="text-align: center"><h4>2.</h4></td>
    <td style="text-align: center"><h4><a href="https://www.tensorflow.org/api_docs">TensorFlow</a></h4></td>
  </tr>
  <tr>
    <td style="text-align: center"><h4>3.</h4></td>
    <td style="text-align: center"><h4><a href="https://spacy.io/usage">Spacy</a></h4></td>
  </tr>
</table>
</p>



<h2><b>Steps to Execute</b></h2>

<h4>
<p>	
1. Download the <i>bbc-text.csv</i> dataset from <a href="https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv">here</a> or it can be downloaded through the terminal if gcloud is already setup by the command:<br>
<code>gsutil cp gs:​//​dataset-uploader​/bbc/​bbc-text.csv [path to notebook directory]</code>
</p>
<p>
2. Make sure all the libraries are present/updated according to the <u>requirements</u> mentioned above.
</p>
<p>
3. To train the model according to the above complete dataset using FastText, run the notebook given <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/fasttext/python/2020/05/20/fasttext-model-train.html">here</a>. A pre-trained model (2.4 GB size) based on the same dataset can be downloaded from <a href="https://learnermanipal-my.sharepoint.com/:u:/g/personal/rohit_rajesh_learner_manipal_edu/EXiXnzOeVN9KsdWpoFgr4CABfblCuo8RamsdLM9NUyatyA?e=yjkplM">here</a>.
</p>
<p>
According to the FastText documentation:
</p>
<p>
<blockquote><h4>The most important parameters of the model are its dimension and the range of size for the subwords. The dimension controls the size of the vectors, the larger they are the more information they can capture but requires more data to be learned. As any value in the 100-300 range is popular, the notebook has been implemented with a dimension equal to 300.</h4></blockquote>
</p>
<p>
<b>Steps 4,5 and 6 differ for TF1 and TF 2. After that, the steps are the same.</b>
</p>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF1 [<font color='red'>NOT ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb1files</u> in the same directory of the notebooks​ and keep it empty. It will store all the TensorFlow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​present <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb1vis.html">here</a>​.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb1files/</code>
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb1.png" alt="TB1 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF2 [<font color='green'>ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb2files</u> in the same directory of the notebooks​ and keep it empty. It will store all the TensorFlow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​present <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html">here</a>.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb2files/</code>.
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb2.png" alt="TB2 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<p>
7. Open the local host URL link present in the last line. For Example: <code>http://localhost:6008/</code> [in TB1 Command image].
</p>
<p>
8. The local host website shown below will run. From the drop-down which reads Inactive, press and go to Projector as depicted by the arrow in the image below.
</p>

<div style="display: flex; justify-content: center;">
<img src="images/projector.png" alt="Projector Image" style="width: auto; height: 350px;" />
</div>

<p>
9. This will plot the words according to their embedding values shown in the 3D graph of the TensorBoard. The nearest neighbours of a word can be found by typing the word in the search bar, as done for the example <b>‘plea’</b> shown below.
</p>


<div style="display: flex; justify-content: center;">
  <img src="images/tbvis.png" alt = "Visualisation on Tensorboard" style="width: auto; height: 350px;" />
</div>
<br>
 -->
<!--  <p>
<h4>
In <a href="https://verloop.io/">Verloop</a>, we observed that the exploration-pipeline for different intents helped us in seeing a coverage jump of about <b>~10-11%</b> from the dataset the machine learning model wasn't able to cover after it's first run of prediction. This guaranteed the success in working of the pipeline. 
</h4>
</p>
<p>
<h4>
To begin with the execution, it is important to know the pre-requisites which can be known from <a href="https://rohetoric.github.io/text-vector-visualisation/markdown/jupyter/fasttext/tensorflow/tensorboard/2020/05/18/ExecutionSteps.html">here</a>.
</h4>
</p>

<hr>

</body>
<h1> Posts </h1> -->
---
layout: home
search_exclude: true
---
<html>
<!-- 
<style>
	table, th, td {
    width: 50%;
    margin-left: auto;
    margin-right: auto;
    border: 1px solid black;
    border-collapse: collapse;
}
</style> -->



<body>
<center><h1><b>Exploration and Visualisation Of Word Vectors in Chat</b></h1></center>

<p>
<h4>
At <a href="https://verloop.io/">Verloop</a>, we observed that the exploration-pipeline for different intents helped us in seeing a coverage jump of about <b>~10-11%</b> from the dataset the machine learning model wasn't able to cover after it's first run of prediction. This is because, we weren't extracting misspellings and paraphrased sentences of the intents before.
</h4>
</p>

<p>
<h4>
Although the data used for the pipeline in this blog-post is based on the articles printed in BBC newspapers, the underlying logic replicates to chat data as well.
For example, the intent <i><u>exchange</u></i> found in chat queries of E-Commerce companies like Amazon can be misspelled and written as:
<ol>
<li><i>Order hasn't been <u>exchanged</u> yet!</i></li>
<li><i>Please <u>ex change</u> my product.</i></li>
<li><i>Expecting <u>exch</u> to take place by Thursday.</i></li>
</ol>
</h4>
</p>


<p>
<h4>
or the same intent can be paraphrased as:
<ol>
<li><i><u>Change</u> my product. It is not working.</i></li>
<li><i>I had issued a <u>replacement</u>. What is its status?</i></li>
</ol> 
</h4>
</p>

<p>
<h4>
 It is not feasible to use <a href="https://pypi.org/project/textdistance/">Edit-distance based, Token based, and Sequence-based algorithmic approaches</a> to cover all the misspellings as well as paraphrased sentences of an intent in the dataset. The exploration-pipeline, here, can do that, increasing the coverage of the intent in the dataset.  
</h4>
</p>

<p>
<h4>The exploration-pipeline is diagrammatically represented as:</h4>
</p>

<div style="display: flex; justify-content: center;">
  <img src="images/flowchart.png" alt = "Flowchart" style="width: auto; height: 170px; border: 1px;" />
</div>

<p>
<h4>
A popular idea in machine learning is to represent words by vectors. FastText vectors capture hidden information about a language, like <b><i>word analogies</i></b> or <b><i>semantic inforamtion</i></b>.
</h4>
</p>

<p>
<h4>
The word analogies and semantic information help us in :
<ol>
<li>Finding and extracting misspellings of a target word in the entire dataset.</li>
<li>Finding words that occur commonly in context (in neighbour) to the target word.</li>
<li>Finding similarity between different words given as a cosine of the angle between the word vectors.</li>
</ol>
</h4>
</p>

<p>
<h4>
Visualisation on TensorBoard gives us a 3-dimensional view of a 300-dimensional FastText word vector. It makes us visualise the top misspellings and the closest neighbouring words of a target intent, increasing the coverage of the intent in the dataset. 
</h4>
</p>

<p>
<h4>
To begin with the execution, it is important to know the pre-requisites and execution steps which can be found <a href="https://rohetoric.github.io/text-vector-visualisation/markdown/jupyter/fasttext/tensorflow/tensorboard/2020/05/18/ExecutionSteps.html">here</a>.
</h4>
</p>

<hr>

</body>
<h1> Posts </h1>

<!-- <p>
<h4>
This practice is beneficial when we want to cover the maximum number of sentences which have the same semantic information or intent in the dataset. This is called <b>coverage</b> of the intent in the dataset. By using the exploration-pipeline [shown below], the coverage for an intent can be increased.
</h4>
</p>

 
 -->









<!-- <h2><b>Requirements and Dependencies</b></h2>



<h4>To run the code the following are a <b><i>must</i></b> to be installed:</h4>

<p>   
<table>
  <tr>
    <th><h4><b>Serial No</b></h4></th>
    <th><h4><b>Libraries to Install</b></h4></th> 
  </tr>
  <tr>
    <td style="text-align: center"><h4>1.</h4></td>
    <td style="text-align: center"><h4><a href="https://fasttext.cc/docs/en/support.html">FastText</a></h4></td>  
  </tr>
  <tr>
    <td style="text-align: center"><h4>2.</h4></td>
    <td style="text-align: center"><h4><a href="https://www.tensorflow.org/api_docs">TensorFlow</a></h4></td>
  </tr>
  <tr>
    <td style="text-align: center"><h4>3.</h4></td>
    <td style="text-align: center"><h4><a href="https://spacy.io/usage">Spacy</a></h4></td>
  </tr>
</table>
</p>



<h2><b>Steps to Execute</b></h2>

<h4>
<p>	
1. Download the <i>bbc-text.csv</i> dataset from <a href="https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv">here</a> or it can be downloaded through the terminal if gcloud is already setup by the command:<br>
<code>gsutil cp gs:​//​dataset-uploader​/bbc/​bbc-text.csv [path to notebook directory]</code>
</p>
<p>
2. Make sure all the libraries are present/updated according to the <u>requirements</u> mentioned above.
</p>
<p>
3. To train the model according to the above complete dataset using FastText, run the notebook given <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/fasttext/python/2020/05/20/fasttext-model-train.html">here</a>. A pre-trained model (2.4 GB size) based on the same dataset can be downloaded from <a href="https://learnermanipal-my.sharepoint.com/:u:/g/personal/rohit_rajesh_learner_manipal_edu/EXiXnzOeVN9KsdWpoFgr4CABfblCuo8RamsdLM9NUyatyA?e=yjkplM">here</a>.
</p>
<p>
According to the FastText documentation:
</p>
<p>
<blockquote><h4>The most important parameters of the model are its dimension and the range of size for the subwords. The dimension controls the size of the vectors, the larger they are the more information they can capture but requires more data to be learned. As any value in the 100-300 range is popular, the notebook has been implemented with a dimension equal to 300.</h4></blockquote>
</p>
<p>
<b>Steps 4,5 and 6 differ for TF1 and TF 2. After that, the steps are the same.</b>
</p>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF1 [<font color='red'>NOT ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb1files</u> in the same directory of the notebooks​ and keep it empty. It will store all the TensorFlow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​present <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb1vis.html">here</a>​.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb1files/</code>
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb1.png" alt="TB1 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<center>
<h3><b>To Visualise Embeddings Using TF2 [<font color='green'>ADVISED</font>]</b></h3>
</center>

<p>
4. Create a folder called <u>tb2files</u> in the same directory of the notebooks​ and keep it empty. It will store all the TensorFlow log files after step 5 is run.
</p>
<p>
5. Run the notebook ​present <a href="https://rohetoric.github.io/text-vector-visualisation/jupyter/tensorflow/python/2020/05/21/tb2vis.html">here</a>.
</p>
<p>
6. Set the terminal address path to the directory where the files are stored in the terminal and type the command: <code>tensorboard ​--logdir tb2files/</code>.
</p>
<p>
The above command would yield a result:
</p>

<div style="display: flex; justify-content: center;">
<img src="images/cmdtb2.png" alt="TB2 Terminal Command" style="width: auto; height: 250px;" /> 
</div>

<hr>

<p>
7. Open the local host URL link present in the last line. For Example: <code>http://localhost:6008/</code> [in TB1 Command image].
</p>
<p>
8. The local host website shown below will run. From the drop-down which reads Inactive, press and go to Projector as depicted by the arrow in the image below.
</p>

<div style="display: flex; justify-content: center;">
<img src="images/projector.png" alt="Projector Image" style="width: auto; height: 350px;" />
</div>

<p>
9. This will plot the words according to their embedding values shown in the 3D graph of the TensorBoard. The nearest neighbours of a word can be found by typing the word in the search bar, as done for the example <b>‘plea’</b> shown below.
</p>


<div style="display: flex; justify-content: center;">
  <img src="images/tbvis.png" alt = "Visualisation on Tensorboard" style="width: auto; height: 350px;" />
</div>
<br>
 -->
<!--  <p>
<h4>
In <a href="https://verloop.io/">Verloop</a>, we observed that the exploration-pipeline for different intents helped us in seeing a coverage jump of about <b>~10-11%</b> from the dataset the machine learning model wasn't able to cover after it's first run of prediction. This guaranteed the success in working of the pipeline. 
</h4>
</p>
<p>
<h4>
To begin with the execution, it is important to know the pre-requisites which can be known from <a href="https://rohetoric.github.io/text-vector-visualisation/markdown/jupyter/fasttext/tensorflow/tensorboard/2020/05/18/ExecutionSteps.html">here</a>.
</h4>
</p>

<hr>

</body>
<h1> Posts </h1> -->
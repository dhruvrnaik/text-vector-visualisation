{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Word Vectors Using FastText Blog-Post\n",
    "> Conversion of words in the vocabulary of the dataset to vectors using FastText.\n",
    "\n",
    "- toc: false \n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [jupyter,fasttext,python]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"FastText\"](my_icons/fasttext.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset can be downloaded through:\n",
    "\n",
    "1. Terminal:\n",
    "`gsutil cp gs://dataset-uploader/bbc/bbc-text.csv`\n",
    "\n",
    "                     OR\n",
    "\n",
    "2. Visiting this [website](https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv) from the browser.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_csv(\"bbc-text.csv\")  # reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>business</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2221</td>\n",
       "      <td>politics</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2222</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2223</td>\n",
       "      <td>politics</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2224</td>\n",
       "      <td>sport</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           category                                               text\n",
       "0              tech  tv future in the hands of viewers with home th...\n",
       "1          business  worldcom boss  left books alone  former worldc...\n",
       "2             sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3             sport  yeading face newcastle in fa cup premiership s...\n",
       "4     entertainment  ocean s twelve raids box office ocean s twelve...\n",
       "...             ...                                                ...\n",
       "2220       business  cars pull down us retail figures us retail sal...\n",
       "2221       politics  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  entertainment  rem announce new glasgow concert us band rem h...\n",
       "2223       politics  how political squabbles snowball it s become c...\n",
       "2224          sport  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"category\"], inplace=True)  # don't need the labels for the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>cars pull down us retail figures us retail sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2221</td>\n",
       "      <td>kilroy unveils immigration policy ex-chatshow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2222</td>\n",
       "      <td>rem announce new glasgow concert us band rem h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2223</td>\n",
       "      <td>how political squabbles snowball it s become c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2224</td>\n",
       "      <td>souness delight at euro progress boss graeme s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "0     tv future in the hands of viewers with home th...\n",
       "1     worldcom boss  left books alone  former worldc...\n",
       "2     tigers wary of farrell  gamble  leicester say ...\n",
       "3     yeading face newcastle in fa cup premiership s...\n",
       "4     ocean s twelve raids box office ocean s twelve...\n",
       "...                                                 ...\n",
       "2220  cars pull down us retail figures us retail sal...\n",
       "2221  kilroy unveils immigration policy ex-chatshow ...\n",
       "2222  rem announce new glasgow concert us band rem h...\n",
       "2223  how political squabbles snowball it s become c...\n",
       "2224  souness delight at euro progress boss graeme s...\n",
       "\n",
       "[2225 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tv future hands viewers home theatre systems plasma highdefinition tvs digital video recorders moving living room way people watch tv radically different years time according expert panel gathered annual consumer electronics las vegas discuss new technologies impact favourite pastimes leading trend programmes content delivered viewers home networks cable satellite telecoms companies broadband service providers rooms portable devices talkedabout technologies ces digital personal video recorders dvr pvr settop boxes like s tivo uk s sky system allow people record store play pause forward wind tv programmes want essentially technology allows personalised tv builtin highdefinition tv sets big business japan slower europe lack highdefinition programming people forward wind adverts forget abiding network channel schedules putting alacarte entertainment networks cable satellite companies worried means terms advertising revenues brand identity viewer loyalty channels leads technology moment concern raised europe particularly growing uptake services like sky happens today months years time uk adam hume bbc broadcast s futurologist told bbc news website likes bbc issues lost advertising revenue pressing issue moment commercial uk broadcasters brand loyalty important talking content brands network brands said tim hanlon brand communications firm starcom mediavest reality broadband connections anybody producer content added challenge hard promote programme choice means said stacey jolna senior vice president tv guide tv group way people find content want watch simplified tv viewers means networks terms channels leaf google s book search engine future instead scheduler help people find want watch kind channel model work younger ipod generation taking control gadgets play suit panel recognised older generations comfortable familiar schedules channel brands know getting want choice hands mr hanlon suggested end kids diapers pushing buttons possible available said mr hanlon ultimately consumer tell market want 50 000 new gadgets technologies showcased ces enhancing tvwatching experience highdefinition tv sets new models lcd liquid crystal display tvs launched dvr capability built instead external boxes example launched humax s 26inch lcd tv 80hour tivo dvr dvd recorder s biggest satellite tv companies directtv launched branded dvr 100hours recording capability instant replay search function set pause rewind tv 90 hours microsoft chief bill gates announced preshow keynote speech partnership tivo called tivotogo means people play recorded programmes windows pcs mobile devices reflect increasing trend freeing multimedia people watch want want'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_string_list = []\n",
    "token_list = []\n",
    "filtered_list = []\n",
    "\n",
    "\n",
    "for query in df[\"text\"]:\n",
    "    \n",
    "    # removing punctuations from string\n",
    "    string_translate = query.translate(\n",
    "        str.maketrans(\"\", \"\", string.punctuation)\n",
    "    )  \n",
    "\n",
    "    # initialise string to english langauge functions of spacy\n",
    "    spacy_doc = nlp(\n",
    "        string_translate\n",
    "    )  \n",
    "\n",
    "    # appending empty list with tokenised string\n",
    "    for token in spacy_doc:\n",
    "        token_list.append(token.text)  \n",
    "\n",
    "    # checking if tokenised word exists in a given list of stopwords obtained     \n",
    "    for word in token_list:\n",
    "        lexeme = nlp.vocab[\n",
    "            word\n",
    "        ]  \n",
    "        if lexeme.is_stop == False:\n",
    "            filtered_list.append(\n",
    "                word\n",
    "            )  \n",
    "\n",
    "    # converting list of tokenised words without stopwords to sentence\n",
    "    filtered_sentence = \" \".join(\n",
    "        filtered_list\n",
    "    )  \n",
    "\n",
    "    # removing multiple spaces from the string\n",
    "    filtered_sentence = re.sub(\n",
    "        \" +\", \" \", filtered_sentence\n",
    "    )  \n",
    "\n",
    "    # appending the list with strings without stop words\n",
    "    refined_string_list.append(\n",
    "        filtered_sentence\n",
    "    )  \n",
    "\n",
    "    # reinitialising the lists\n",
    "    token_list = []\n",
    "    filtered_list = []\n",
    "\n",
    "\n",
    "refined_string_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"refined-bbc-text.txt\", \"w\") as f:\n",
    "    for item in refined_string_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <--TRAINING THE MODEL BASED ON FASTTEXT-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Train an unsupervised model and return a model object.\n",
      "\n",
      "    input must be a filepath. The input text does not need to be tokenized\n",
      "    as per the tokenize function, but it must be preprocessed and encoded\n",
      "    as UTF-8. You might want to consult standard preprocessing scripts such\n",
      "    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n",
      "\n",
      "    The input field must not contain any labels or use the specified label prefix\n",
      "    unless it is ok for those words to be ignored. For an example consult the\n",
      "    dataset pulled by the example script word-vector-example.sh, which is\n",
      "    part of the fastText repository.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(fasttext.train_unsupervised.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Default Configuration for parameters mentioned in [ ] for fasttext.train_unsupervised(): \n",
    "\n",
    "    input             # training file path (required)\n",
    "    model             # unsupervised fasttext model {cbow, skipgram} [skipgram]\n",
    "    lr                # learning rate [0.05]\n",
    "    dim               # size of word vectors [100]\n",
    "    ws                # size of the context window [5]\n",
    "    epoch             # number of epochs [5]\n",
    "    minCount          # minimal number of word occurences [5]\n",
    "    minn              # min length of char ngram [3]\n",
    "    maxn              # max length of char ngram [6]\n",
    "    neg               # number of negatives sampled [5]\n",
    "    wordNgrams        # max length of word ngram [1]\n",
    "    loss              # loss function {ns, hs, softmax, ova} [ns]\n",
    "    bucket            # number of buckets [2000000]\n",
    "    lrUpdateRate      # change the rate of updates for the learning rate [100]\n",
    "    t                 # sampling threshold [0.0001]\n",
    "    verbose           # verbose [2]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 1.14 s, total: 2min 35s\n",
      "Wall time: 46.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = fasttext.train_unsupervised(\"refined-bbc-text.txt\", dim=300, thread=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tensorboard/metadata.tsv\", \"w\") as f:\n",
    "    for item in model.words:\n",
    "        f.write(\n",
    "            \"%s\\n\" % item\n",
    "        )  # writing the vocabulary words of the model to a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"fasttextmodel.bin\")  # saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
